{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "personality_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pQtRdf4USVB",
        "outputId": "385520fa-6b88-49b4-a55d-3efac35a5fba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yb-sAZn57UWu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from wordcloud import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import tensorflow as tf\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing data"
      ],
      "metadata": {
        "id": "5hTOgDMC79Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"mbti_1.csv\")\n",
        "data_processing=data['posts']\n",
        "y=data.drop('posts',axis='columns')\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-m0W1xX7_Wj",
        "outputId": "87d20b9d-e773-48b3-a21e-ec9c94e6daaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type\n",
              "INFP    1832\n",
              "INFJ    1470\n",
              "INTP    1304\n",
              "INTJ    1091\n",
              "ENTP     685\n",
              "ENFP     675\n",
              "ISTP     337\n",
              "ISFP     271\n",
              "ENTJ     231\n",
              "ISTJ     205\n",
              "ENFJ     190\n",
              "ISFJ     166\n",
              "ESTP      89\n",
              "ESFP      48\n",
              "ESFJ      42\n",
              "ESTJ      39\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning data "
      ],
      "metadata": {
        "id": "IAMTjKiz-fKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(data):\n",
        "  clean_data=[]\n",
        "  lm=WordNetLemmatizer()\n",
        "  for i in range(len(data)):\n",
        "    text=re.sub(r\"[|,'@$&!*;\\\"]\",\" \",data[i])\n",
        "    text=re.sub(r'http ://([^\\s]+)',' ',text)\n",
        "    text=re.sub(r'http://([^\\s]+)',' ',text)\n",
        "    text=re.sub(r'https://([^\\s]+)',' ',text)\n",
        "    text=re.sub(r\"['-:,'_?./%?0-9(),]\",\" \",text)\n",
        "    text=text.lower()\n",
        "    text=text.split()\n",
        "    for word in text:\n",
        "      word=lm.lemmatize(word)\n",
        "    text=list(set(text)-STOPWORDS)\n",
        "    text=\" \".join(text)\n",
        "    clean_data.append(text)\n",
        "  return clean_data\n",
        "sentences=cleaning(data_processing)"
      ],
      "metadata": {
        "id": "RPH1-yT5-etA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating tokens of data ( creating matrix of words)"
      ],
      "metadata": {
        "id": "BO4zdabIT3Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer(max_features=5000)\n",
        "x=cv.fit_transform(sentences).toarray()"
      ],
      "metadata": {
        "id": "Jt12oVLQT2UT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoding catagorical data "
      ],
      "metadata": {
        "id": "3DQtEpcKHTPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le=LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1gA0Kc7mgP2",
        "outputId": "a9a5d5d5-281e-4168-98e5-e29f4a08bfe0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tackling imbalence in data"
      ],
      "metadata": {
        "id": "a3IHXbQTUz4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote=SMOTE()\n",
        "x_sm,y_sm=smote.fit_resample(x,y)"
      ],
      "metadata": {
        "id": "eeO9qD__UzUv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=pd.DataFrame(y_sm)\n",
        "a.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttc8l-xtV1JJ",
        "outputId": "48ebaa42-71e5-43a6-816b-ece5f01e9233"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15    1832\n",
              "14    1832\n",
              "13    1832\n",
              "12    1832\n",
              "11    1832\n",
              "10    1832\n",
              "9     1832\n",
              "8     1832\n",
              "7     1832\n",
              "6     1832\n",
              "5     1832\n",
              "4     1832\n",
              "3     1832\n",
              "2     1832\n",
              "1     1832\n",
              "0     1832\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting data into test and training set"
      ],
      "metadata": {
        "id": "S2zkXSuYbwtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x_sm,y_sm,test_size=0.3,random_state=0)"
      ],
      "metadata": {
        "id": "VlaQlMWFbwi7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-fold cross-validation with Grid search"
      ],
      "metadata": {
        "id": "ChAK2_KOcZCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameter=[{'n_estimators':[100,150],\n",
        "            'criterion':['gini'],\n",
        "           'max_features':['sqrt','log2']}]\n",
        "gs=GridSearchCV(estimator=rf,param_grid=parameter,scoring='accuracy',cv=5)\n",
        "gs.fit(xtrain,ytrain)\n",
        "best_acc=gs.best_score_\n",
        "beat_param=gs.best_params_\n",
        "print('Best Accuracy: {:.2f} %'.format(best_acc*100) )\n",
        "print('best param:',beat_param )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azyppeUEi1zt",
        "outputId": "eebdf97b-9cd7-4fa0-c014-09816ebe1c52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 81.72 %\n",
            "best param: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model"
      ],
      "metadata": {
        "id": "V5y0_5I_bYeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf=RandomForestClassifier(n_estimators=150,criterion='gini',max_features='sqrt')\n",
        "rf.fit(xtrain,ytrain)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2ikM3rjbX9u",
        "outputId": "f9b2f414-6008-4ca7-82e9-1edde15ffc60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_features='sqrt', n_estimators=150)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=rf.predict(xtest)"
      ],
      "metadata": {
        "id": "QYJGW3MhnFZF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*le.inverse_transform([ypred[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZi2SUQHhIJj",
        "outputId": "007e0dad-5e16-4f75-a66d-f7867d334d65"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "2ZhPDjxDbUnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest,ypred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj0ecSFYbSiH",
        "outputId": "733359c5-fd06-411b-ee16-e81cbbd305db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94       528\n",
            "           1       0.97      0.64      0.77       544\n",
            "           2       0.99      0.88      0.93       568\n",
            "           3       0.86      0.68      0.76       547\n",
            "           4       1.00      0.99      0.99       573\n",
            "           5       1.00      0.98      0.99       545\n",
            "           6       0.99      0.98      0.99       567\n",
            "           7       1.00      0.96      0.98       536\n",
            "           8       0.50      0.63      0.56       573\n",
            "           9       0.36      0.84      0.51       556\n",
            "          10       0.87      0.53      0.66       565\n",
            "          11       0.56      0.62      0.59       497\n",
            "          12       1.00      0.92      0.96       538\n",
            "          13       1.00      0.86      0.92       557\n",
            "          14       1.00      0.91      0.95       539\n",
            "          15       1.00      0.83      0.90       561\n",
            "\n",
            "    accuracy                           0.82      8794\n",
            "   macro avg       0.88      0.82      0.84      8794\n",
            "weighted avg       0.88      0.82      0.84      8794\n",
            "\n"
          ]
        }
      ]
    }
  ]
}